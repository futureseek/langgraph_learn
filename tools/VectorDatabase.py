import os
import json
import hashlib
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
import chromadb.utils.embedding_functions as embedding_functions
from langchain_community.embeddings import OllamaEmbeddings
class VectorDatabase:
    """
    å‘é‡æ•°æ®åº“ç®¡ç†å™¨ - åŸºäºChromaDBå®ç°RAGåŠŸèƒ½
    """
    
    def __init__(self, 
                 persist_directory: str = "./rag_data/vector_db",
                 collection_name: str = "documents",
                 embedding_model: str = "embeddinggemma:300m"):
        """
        åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        
        Args:
            persist_directory: æ•°æ®åº“æŒä¹…åŒ–ç›®å½•
            collection_name: é›†åˆåç§°
            embedding_model: åµŒå…¥æ¨¡å‹åç§°
        """
        self.persist_directory = Path(persist_directory)
        self.persist_directory.mkdir(parents=True, exist_ok=True)
        
        self.collection_name = collection_name
        self.embedding_model_name = embedding_model
        
        # # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        # self.embeddings = HuggingFaceEmbeddings(
        #     model_name=embedding_model,
        #     model_kwargs={'device': 'cpu'},
        #     encode_kwargs={'normalize_embeddings': True}
        # )
        self.embeddings = OllamaEmbeddings(model="embeddinggemma:300m")  # æˆ–è€… qwen2-embeddings
        # self.embeddings = embedding_functions.OllamaEmbeddingFunction(
        #     url="http://localhost:11434/api/embeddings",
        #     model_name="embeddinggemma:300m",
        # )
        
        # åˆå§‹åŒ–ChromaDBå®¢æˆ·ç«¯
        self.client = chromadb.PersistentClient(
            path=str(self.persist_directory),
            settings=Settings(
                anonymized_telemetry=False,
                allow_reset=True
            )
        )
        
        # è·å–æˆ–åˆ›å»ºé›†åˆ
        try:
            self.collection = self.client.get_collection(name=collection_name)
            print(f"âœ… å·²è¿æ¥åˆ°ç°æœ‰é›†åˆ: {collection_name}")
        except Exception:
            # åˆ›å»ºä¸€ä¸ªé›†åˆï¼Œç”¨ä½™å¼¦ç›¸ä¼¼åº¦æœç´¢
            self.collection = self.client.create_collection(
                name=collection_name,
                metadata={"hnsw:space": "cosine"}
            )
            print(f"âœ… å·²åˆ›å»ºæ–°é›†åˆ: {collection_name}")
        
        # åˆå§‹åŒ–å‘é‡å­˜å‚¨
        self.vector_store = Chroma(
            client=self.client,
            collection_name=collection_name,
            embedding_function=self.embeddings,
            persist_directory=str(self.persist_directory)
        )
        
        # å…ƒæ•°æ®å­˜å‚¨
        self.metadata_file = self.persist_directory / "metadata.json"
        self.metadata = self._load_metadata()
    
    def _load_metadata(self) -> Dict[str, Any]:
        """åŠ è½½å…ƒæ•°æ®"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ åŠ è½½å…ƒæ•°æ®å¤±è´¥: {e}")
        return {
            "documents": {},
            "collections": {},
            "stats": {
                "total_documents": 0,
                "total_chunks": 0,
                "last_updated": None
            }
        }
    
    def _save_metadata(self):
        """ä¿å­˜å…ƒæ•°æ®"""
        try:
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self.metadata, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å…ƒæ•°æ®å¤±è´¥: {e}")
    
    def _calculate_file_hash(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼"""
        try:
            with open(file_path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except Exception:
            return ""
    
    def add_documents(self, documents: List[Document], 
                     source_file: Optional[str] = None) -> bool:
        """
        æ·»åŠ æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            source_file: æºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ·»åŠ 
        """
        try:
            if not documents:
                print("âš ï¸ æ²¡æœ‰æ–‡æ¡£éœ€è¦æ·»åŠ ")
                return False
            
            # âœ… ç¡®ä¿æŒä¹…åŒ–ç›®å½•å­˜åœ¨
            self.persist_directory.mkdir(parents=True, exist_ok=True)
            # âœ… ç¡®ä¿ collection å·²åˆå§‹åŒ–
            if not hasattr(self, "collection") or self.collection is None:
                try:
                    self.collection = self.client.get_collection(name=self.collection_name)
                except Exception:
                    self.collection = self.client.create_collection(
                        name=self.collection_name,
                        metadata={"hnsw:space": "cosine"}
                    )
                    
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²æ›´æ–°
            if source_file and os.path.exists(source_file):
                file_hash = self._calculate_file_hash(source_file)
                file_key = os.path.abspath(source_file)
                
                if file_key in self.metadata["documents"]:
                    if self.metadata["documents"][file_key]["hash"] == file_hash:
                        print(f"ğŸ“„ æ–‡ä»¶æœªå˜æ›´ï¼Œè·³è¿‡å¤„ç†: {os.path.basename(source_file)}")
                        return True
                    else:
                        # æ–‡ä»¶å·²æ›´æ–°ï¼Œå…ˆåˆ é™¤æ—§çš„å—
                        self._remove_document(file_key)
                
                # æ›´æ–°å…ƒæ•°æ®
                self.metadata["documents"][file_key] = {
                    "hash": file_hash,
                    "chunks": len(documents),
                    "processed_at": str(Path().absolute())
                }
            
            # ä¸ºæ¯ä¸ªæ–‡æ¡£æ·»åŠ å”¯ä¸€IDå’Œå…ƒæ•°æ®
            doc_ids = []
            for i, doc in enumerate(documents):
                doc_id = f"{hashlib.md5(doc.page_content.encode()).hexdigest()}_{i}"
                doc_ids.append(doc_id)
                
                # å¢å¼ºæ–‡æ¡£å…ƒæ•°æ®
                if source_file:
                    doc.metadata.update({
                        "source_file": os.path.abspath(source_file),
                        "chunk_index": i,
                        "doc_id": doc_id
                    })
                else:
                    doc.metadata.update({
                        "chunk_index": i,
                        "doc_id": doc_id
                    })
            
            # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
            self.vector_store.add_documents(documents, ids=doc_ids)
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.metadata["stats"]["total_chunks"] += len(documents)
            if source_file:
                self.metadata["stats"]["total_documents"] += 1
            
            self._save_metadata()
            
            print(f"âœ… æˆåŠŸæ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£å—åˆ°å‘é‡æ•°æ®åº“")
            return True
            
        except Exception as e:
            print(f"âŒ æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            return False
    
    def _remove_document(self, file_key: str):
        """åˆ é™¤æŒ‡å®šæ–‡ä»¶çš„æ‰€æœ‰æ–‡æ¡£å—"""
        try:
            # æŸ¥è¯¢è¯¥æ–‡ä»¶çš„æ‰€æœ‰æ–‡æ¡£å—
            results = self.collection.get(
                where={"source_file": file_key}
            )
            
            if results["ids"]:
                # åˆ é™¤æ‰€æœ‰ç›¸å…³çš„æ–‡æ¡£å—
                self.collection.delete(ids=results["ids"])
                print(f"ğŸ—‘ï¸ å·²åˆ é™¤æ–‡ä»¶ {os.path.basename(file_key)} çš„ {len(results['ids'])} ä¸ªæ—§æ–‡æ¡£å—")
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self.metadata["stats"]["total_chunks"] -= len(results["ids"])
                
        except Exception as e:
            print(f"âš ï¸ åˆ é™¤æ—§æ–‡æ¡£å—å¤±è´¥: {e}")
    
    def similarity_search(self, query: str, k: int = 4, 
                         filter_dict: Optional[Dict] = None) -> List[Document]:
        """
        ç›¸ä¼¼æ€§æœç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            k: è¿”å›ç»“æœæ•°é‡
            filter_dict: è¿‡æ»¤æ¡ä»¶
            
        Returns:
            List[Document]: ç›¸å…³æ–‡æ¡£åˆ—è¡¨
        """
        try:
            # ä½¿ç”¨å‘é‡å­˜å‚¨è¿›è¡Œæœç´¢
            if filter_dict:
                results = self.vector_store.similarity_search(
                    query, k=k, filter=filter_dict
                )
            else:
                results = self.vector_store.similarity_search(query, k=k)
            
            return results
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return []
    
    def similarity_search_with_score(self, query: str, k: int = 4) -> List[Tuple[Document, float]]:
        """
        å¸¦ç›¸ä¼¼åº¦åˆ†æ•°çš„æœç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            List[Tuple[Document, float]]: (æ–‡æ¡£, ç›¸ä¼¼åº¦åˆ†æ•°) åˆ—è¡¨
        """
        try:
            results = self.vector_store.similarity_search_with_score(query, k=k)
            return results
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return []
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        try:
            collection_count = self.collection.count()
            return {
                "collection_name": self.collection_name,
                "total_documents": len(self.metadata["documents"]),
                "total_chunks": collection_count,
                "embedding_model": self.embedding_model_name,
                "persist_directory": str(self.persist_directory)
            }
        except Exception as e:
            print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def list_documents(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰å·²ç´¢å¼•çš„æ–‡æ¡£"""
        documents = []
        for file_path, info in self.metadata["documents"].items():
            documents.append({
                "file_path": file_path,
                "chunks": info["chunks"],
                "processed_at": info.get("processed_at", "æœªçŸ¥"),
                "file_name": os.path.basename(file_path)
            })
        return documents
    
    def delete_document(self, file_path: str) -> bool:
        """
        åˆ é™¤æŒ‡å®šæ–‡æ¡£
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆ é™¤
        """
        try:
            file_key = os.path.abspath(file_path)
            if file_key not in self.metadata["documents"]:
                print(f"âš ï¸ æ–‡æ¡£ä¸å­˜åœ¨: {file_path}")
                return False
            
            self._remove_document(file_key)
            
            # ä»å…ƒæ•°æ®ä¸­åˆ é™¤
            del self.metadata["documents"][file_key]
            self.metadata["stats"]["total_documents"] -= 1
            
            self._save_metadata()
            
            print(f"âœ… æˆåŠŸåˆ é™¤æ–‡æ¡£: {os.path.basename(file_path)}")
            return True
            
        except Exception as e:
            print(f"âŒ åˆ é™¤æ–‡æ¡£å¤±è´¥: {e}")
            return False
    
    def clear_all(self) -> bool:
        """å½»åº•æ¸…ç©ºæ‰€æœ‰æ•°æ®ï¼ŒåŒ…æ‹¬ collection å’Œ SQLite æ–‡ä»¶"""
        try:
            # å…ˆå°è¯•åˆ é™¤é›†åˆï¼ˆé€»è¾‘å±‚ï¼‰
            try:
                self.client.delete_collection(name=self.collection_name)
            except Exception:
                pass  # é›†åˆå¯èƒ½ä¸å­˜åœ¨ï¼Œå¿½ç•¥

            self.close()
            # 1ï¸âƒ£ åˆ é™¤æ•´ä¸ªæŒä¹…åŒ–ç›®å½•
            if self.persist_directory.exists():
                import shutil
                shutil.rmtree(self.persist_directory)
                print(f"ğŸ—‘ï¸ å·²åˆ é™¤æŒä¹…åŒ–ç›®å½•: {self.persist_directory}")

            # 2ï¸âƒ£ é‡æ–°åˆ›å»ºæŒä¹…åŒ–ç›®å½•
            self.persist_directory.mkdir(parents=True, exist_ok=True)

            # 3ï¸âƒ£ é‡å»º ChromaDB å®¢æˆ·ç«¯
            self.client = chromadb.PersistentClient(
                path=str(self.persist_directory),
                settings=Settings(
                    anonymized_telemetry=False,
                    allow_reset=True
                )
            )

            # 4ï¸âƒ£ é‡æ–°åˆ›å»º collection
            self.collection = self.client.create_collection(
                name=self.collection_name,
                metadata={"hnsw:space": "cosine"}
            )

            # 5ï¸âƒ£ é‡æ–°åˆå§‹åŒ–å‘é‡å­˜å‚¨
            self.vector_store = Chroma(
                client=self.client,
                collection_name=self.collection_name,
                embedding_function=self.embeddings,
                persist_directory=str(self.persist_directory)
            )

            # 6ï¸âƒ£ æ¸…ç©ºå…ƒæ•°æ®å¹¶ä¿å­˜
            self.metadata = {
                "documents": {},
                "collections": {},
                "stats": {
                    "total_documents": 0,
                    "total_chunks": 0,
                    "last_updated": None
                }
            }
            self._save_metadata()

            print("âœ… å·²å½»åº•æ¸…ç©ºæ‰€æœ‰æ•°æ®ï¼ŒåŒ…æ‹¬ SQLite æ–‡ä»¶å’Œ collection")
            return True

        except Exception as e:
            print(f"âŒ æ¸…ç©ºæ•°æ®å¤±è´¥: {e}")
            return False
        
    def close(self):
        """
        ä¸»åŠ¨é‡Šæ”¾/å…³é—­ Chroma å®¢æˆ·ç«¯ï¼Œè§£é™¤ SQLite æ–‡ä»¶é”ã€‚
        """
        try:
            # Chroma çš„ PersistentClient æ²¡æœ‰æ˜¾å¼ close æ–¹æ³•
            # æ‰€ä»¥å¯ä»¥ç”¨ del + å¼ºåˆ¶ GC è§¦å‘å…³é—­
            import gc
            del self.client
            del self.collection
            gc.collect()
            print("VectorDatabase å·²å…³é—­ï¼ŒSQLite æ–‡ä»¶é”å·²é‡Šæ”¾ã€‚")
        except Exception as e:
            print(f"å…³é—­ VectorDatabase å‡ºé”™: {e}")

def create_vector_database(persist_directory: str = "./rag_data/vector_db",
                          collection_name: str = "documents") -> VectorDatabase:
    """
    åˆ›å»ºå‘é‡æ•°æ®åº“å®ä¾‹
    
    Args:
        persist_directory: æŒä¹…åŒ–ç›®å½•
        collection_name: é›†åˆåç§°
        
    Returns:
        VectorDatabase: å‘é‡æ•°æ®åº“å®ä¾‹
    """
    return VectorDatabase(
        persist_directory=persist_directory,
        collection_name=collection_name
    )